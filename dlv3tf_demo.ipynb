{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV3 Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section has references to papers and code that I have used to put together this demo. Some of the code comes directly from other open source repos and in some cases I have modified it.  I have tried to give credit to all of the sources but if you see something that needs to be added, just let me know\n",
    "\n",
    "* Google's DeepLabV3 repository. https://github.com/tensorflow/models/tree/master/research/deeplab\n",
    "* Extract a mask from DeepLabV3 segmentation. https://stackoverflow.com/questions/52113864/extract-image-segmentation-map-from-tensorflow-deeplab-v3-demo\n",
    "* Transfer learning using DeepLabV3. https://expoundai.wordpress.com/2019/08/30/transfer-learning-for-segmentation-using-deeplabv3-in-pytorch/\n",
    "ipython widgets. https://ipywidgets.readthedocs.io/en/latest/\n",
    "* Google Colab off the shelf notebook to test DeepLabV3. https://github.com/tensorflow/models/blob/master/research/deeplab/deeplab_demo.ipynb\n",
    "* Python `tempfile` module. https://docs.python.org/2/library/tempfile.html\n",
    "* Python `urlib` module. https://docs.python.org/2/library/urllib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "The software requirements for this notebook to run (Python packages) are in the `dlv3tf` conda environment. Some specific things:\n",
    "\n",
    "* This notebook uses Tensor Flow 1.x, more specifically 1.15. Tensor Flow 2.0 is released, but this notebook (and Google's current (main branch) DeepLabV3 code only works with TF 1.15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "from IPython import display\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import interactive\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow Version: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample page for the DeepLabV3 has a Colab notebook that has a class to implement the model and run inference. At this time I am going to just re-use the code from the Google page here. Most everybody that I have seen simply re-uses this code, there is really nothing more than I can add.  \n",
    "\n",
    "I may, however simplity it or slightly adapt it for my configuration.  In any case much of the code in the next section (`class DeepLab` model comes from https://github.com/tensorflow/models/blob/master/research/deeplab/deeplab_demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabModel(object):\n",
    "  \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
    "\n",
    "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "  INPUT_SIZE = 513\n",
    "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "  def __init__(self, tarball_path):\n",
    "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "    self.graph = tf.Graph()\n",
    "\n",
    "    graph_def = None\n",
    "    # Extract frozen graph from tar archive.\n",
    "    tar_file = tarfile.open(tarball_path)\n",
    "    for tar_info in tar_file.getmembers():\n",
    "      if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "        file_handle = tar_file.extractfile(tar_info)\n",
    "        graph_def = tf.GraphDef.FromString(file_handle.read())\n",
    "        break\n",
    "\n",
    "    tar_file.close()\n",
    "\n",
    "    if graph_def is None:\n",
    "      raise RuntimeError('Cannot find inference graph in tar archive.')\n",
    "\n",
    "    with self.graph.as_default():\n",
    "      tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    self.sess = tf.Session(graph=self.graph)\n",
    "\n",
    "  def run(self, image):\n",
    "    \"\"\"Runs inference on a single image.\n",
    "\n",
    "    Args:\n",
    "      image: A PIL.Image object, raw input image.\n",
    "\n",
    "    Returns:\n",
    "      resized_image: RGB image resized from original input image.\n",
    "      seg_map: Segmentation map of `resized_image`.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "    batch_seg_map = self.sess.run(\n",
    "        self.OUTPUT_TENSOR_NAME,\n",
    "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "    seg_map = batch_seg_map[0]\n",
    "    return resized_image, seg_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, I will use (first) the Xception backend. It will have to be downloaded. The Colab notebook from Google has some code that allows you to choose a pre-trained model. Since at some point I will want to try other models, I will use use that code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "_MODEL_URLS = {\n",
    "    'mobilenetv2_coco_voctrainaug':\n",
    "        'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "    'mobilenetv2_coco_voctrainval':\n",
    "        'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz',\n",
    "    'xception_coco_voctrainaug':\n",
    "        'deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n",
    "    'xception_coco_voctrainval':\n",
    "        'deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n",
    "}\n",
    "_TARBALL_NAME = 'deeplab_model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the next variable to the name of the model that we want to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'mobilenetv2_coco_voctrainaug'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we want to store the downloaded model. The Google notebook uses a directory in `\\tmp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'tfmodels/'\n",
    "model_dir = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be downloaded to: tfmodels/deeplab_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
    "print(\"Model will be downloaded to:\", download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(_MODEL_URLS[MODEL_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading model, this might take a while...\n",
      "download completed! loading DeepLab model...\n"
     ]
    }
   ],
   "source": [
    "print('downloading model, this might take a while...')\n",
    "urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME],\n",
    "                   download_path)\n",
    "print('download completed! loading DeepLab model...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Loaded Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model. It gets downloaded to a `tmp` directory in `\\tmp\\<generated temp file name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "MODEL = DeepLabModel(download_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
